
#pragma once

#include <iostream>
#include <string>
#include <stdlib.h>
#include <float.h>

namespace gemv{
#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )
inline void __cudaCheckError( const char *file, const int line ) {
    cudaError err = cudaGetLastError();
    if ( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
    // More careful checking. However, this will affect performance.
    // Comment away if needed.
    err = cudaDeviceSynchronize();
    if( cudaSuccess != err )
    {
        fprintf( stderr, "cudaCheckError() with sync failed at %s:%i : %s\n",
                 file, line, cudaGetErrorString( err ) );
        exit( -1 );
    }
}

void cpu_gemm(half *a, half *b, float *c, int M, int N, int K) {
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            float s = 0.0;
            for (int k = 0; k < K; k++) {
                s += (float)a[i * K + k] * (float)b[k + j * K];
            }
            c[i * N + j] = s;
        }
    }
}

bool check_value(float abs_tol, float rel_tol, float *h_d_c, float *h_c, int m, int n) {
    for (size_t i = 0; i < m; i++) {
        for (size_t j = 0; j < n; j++) {
            float gpu_value = h_d_c[i * n + j];
            float cpu_value = h_c[i * n + j];
            float diff = abs(gpu_value - cpu_value);
            if (diff > max(abs_tol, cpu_value * rel_tol)) {
                std::cout << "GPU[" << i << ", " << j << "] = " << gpu_value
                << "CPU[" << i << ", " << j << "] = " << cpu_value
                << " Abs Diff: " << diff << std::endl;
                return false;
            }
        }
    }
    return true;
}
} // namespace gemv
int main(int argc, char **argv) {
    constexpr size_t m = 1;
    constexpr size_t n = 1024;
    constexpr size_t k = 2186;
    constexpr size_t lda = (k + 16 - 1) / 16;
    constexpr size_t ldb = (n + 16 - 1) / 16;
    constexpr size_t ldc = (n + 16 - 1) / 16;
    float alpha = 1.0f;
    float beta = 0.0f;

    size_t size_a = m * k * sizeof(half);
    size_t size_b = k * n * sizeof(half);
    size_t size_c = m * n * sizeof(float);
    
    half *h_a, *h_b, *d_a, *d_b;
    float *h_c, *d_c, *h_d_c;
    
    h_a = (half *)malloc(size_a);
    h_b = (half *)malloc(size_b);
    h_c = (float *)malloc(size_c);
    cudaMalloc(&d_a, size_a);
    cudaMalloc(&d_b, size_b);
    cudaMalloc(&d_c, size_c);
    h_d_c = (float *)malloc(size_c);

    srand(0);
    for (size_t i = 0; i < m * k; i++) {
        h_a[i] = (half)(rand() % 10);
    }
    for (size_t i = 0; i < n * k; i++) {
        h_b[i] = (half)(rand() % 10);
    }

    gemv::cpu_gemm(h_a, h_b, h_c, m, n, k);
    // for (int i = 0; i < 16; i++) {
    //     printf("[");
    //     for (int j = 0; j < n; j++) {
    //         printf("%f, ", h_c[i * n + j]);
    //     }
    //     printf("],\n");
    // }

    cudaMemcpy(d_a, h_a, size_a, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size_b, cudaMemcpyHostToDevice);

    cudaStream_t stream;
    cudaStreamCreate(&stream);
    gemv::launch_gemm(m, n, k, &alpha, d_a, lda, d_b, ldb, &beta, d_c, ldc, stream);
    gemv::CudaCheckError();
    cudaMemcpy(h_d_c, d_c, size_c, cudaMemcpyDeviceToHost);
    // printf("++++++++++++++++++++++++++++++++++\n");
    // for (int i = 0; i < 16; i++) {
    //     printf("[");
    //     for (int j = 0; j < n; j++) {
    //         printf("%f, ", h_d_c[i * n + j]);
    //     }
    //     printf("],\n");
    // }
    
    constexpr float abs_tol = 5.0e-2f;
    constexpr float rel_tol = 1.0e-2f;

    if (gemv::check_value(abs_tol, rel_tol, h_d_c, h_c, m, n)) {
        std::cout << "Test PASSED" << std::endl;
    } else {
        std::cout << "Test FAILED" << std::endl;
    }

    free(h_a);
    free(h_b);
    free(h_c);
    free(h_d_c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
    cudaStreamDestroy(stream);

    return 0;
}